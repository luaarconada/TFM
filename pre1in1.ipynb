{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6587ea7",
   "metadata": {},
   "source": [
    "# Pre1 + in1\n",
    "1. Reweighting + Prejudice Remover\n",
    "2. Disparate Impact Remover + Prejudice Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5cd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PACKAGES\n",
    "\n",
    "# working paths\n",
    "%run code_00_working_paths.py\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(func_path)\n",
    "\n",
    "from load_data import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92301292",
   "metadata": {},
   "source": [
    "## Parameters and preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf71f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PARAMETERS\n",
    "\n",
    "# specify data set\n",
    "# one of ['data1', 'data2', ..., 'data50']\n",
    "data = 'datacorr1'\n",
    "\n",
    "# partitioning\n",
    "num_folds = 10\n",
    "seed      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c84e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PRE-PROCESSOR PARAMS\n",
    "\n",
    "all_lambda = [0.5,0.6,0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d5fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IN-PROCESSOR PARAMS\n",
    "\n",
    "all_eta = [1, 15, 50, 70, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25256b",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d16b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RANDOM SEED\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b999dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 6)\n"
     ]
    }
   ],
   "source": [
    "##### LOAD PARTITIONING\n",
    "\n",
    "# Assuming data is in the format 'dataN' where N is the dataset number\n",
    "dataset_number = data[4:]\n",
    "\n",
    "# Create the directory path (assuming directories data1, data2, ..., data50 already exist)\n",
    "input_dir = os.path.join(data_path, 'prepared')\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(input_dir, data + '_orig_test.pkl')\n",
    "\n",
    "# Load the dataset\n",
    "with open(file_path, 'rb') as file:\n",
    "    dataset_orig_test = pickle.load(file)\n",
    "    \n",
    "# Convert to dataframe and print the shape\n",
    "te = dataset_orig_test.convert_to_dataframe()[0]\n",
    "print(te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eecf97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATA PREP\n",
    "\n",
    "# protected attribute\n",
    "protected           = 'race'\n",
    "privileged_groups   = [{'race': 1}] \n",
    "unprivileged_groups = [{'race': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b192da",
   "metadata": {},
   "source": [
    "## Fair processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d9b93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "- METHOD: RW...\n",
      "------------------------------\n",
      "------------------------------\n",
      "- FOLD 0...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 1...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 2...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 3...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 4...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 5...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 6...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 7...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 8...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 9...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "\n",
      "\n",
      "Finished in 10.72 minutes\n"
     ]
    }
   ],
   "source": [
    "##### MODELING\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# Create the directory path for inprocessor output\n",
    "output_dir = os.path.join(res_path, 'pre1in1')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# preprocessing and inprocessing loop\n",
    "print('-' * 30)\n",
    "print('- METHOD: RW...')\n",
    "print('-' * 30)\n",
    "\n",
    "# loop through fold combinations\n",
    "for fold in range(num_folds):\n",
    "    \n",
    "    # feedback\n",
    "    print('-'*30)\n",
    "    print('- FOLD ' + str(fold) + '...')\n",
    "    print('-'*30)\n",
    "\n",
    "    ##### LOAD DATA\n",
    "    # import data subsets\n",
    "    train_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_train.pkl')\n",
    "    valid_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_valid.pkl')\n",
    "    test_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_test.pkl')\n",
    "\n",
    "    # Load the dataset\n",
    "    with open(train_path, 'rb') as file:\n",
    "        data_train = pickle.load(file)\n",
    "    with open(valid_path, 'rb') as file:\n",
    "        data_valid = pickle.load(file)\n",
    "    with open(test_path, 'rb') as file:\n",
    "        data_test = pickle.load(file)\n",
    "\n",
    "    # Reweighing\n",
    "    RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "    RW.fit(data_train)\n",
    "\n",
    "    # Transform the data\n",
    "    dataset_transf_train = RW.transform(data_train)\n",
    "    dataset_transf_valid = RW.transform(data_valid)\n",
    "    dataset_transf_test = RW.transform(data_test)\n",
    "\n",
    "    ##### IN-PROCESSOR: PREJUDICE REMOVER\n",
    "\n",
    "    # placeholders\n",
    "    pr_predictions_valid = pd.DataFrame()\n",
    "    pr_predictions_test = pd.DataFrame()\n",
    "\n",
    "    for eta in all_eta:\n",
    "        print('--- eta: %.2f' % eta)\n",
    "        colname = 'eta_' + str(eta)\n",
    "\n",
    "        # Fit Prejudice Remover\n",
    "        debiased_model = PrejudiceRemover(eta=eta, sensitive_attr=protected, class_attr='target')\n",
    "        debiased_model.fit(dataset_transf_train)\n",
    "\n",
    "        # Predict validation scores\n",
    "        dataset_debiasing_valid = debiased_model.predict(dataset_transf_valid)\n",
    "        scores = dataset_debiasing_valid.scores\n",
    "        pr_predictions_valid[colname] = sum(scores.tolist(), [])\n",
    "\n",
    "        # Predict test scores\n",
    "        dataset_debiasing_test = debiased_model.predict(dataset_transf_test)\n",
    "        scores = dataset_debiasing_test.scores\n",
    "        pr_predictions_test[colname] = sum(scores.tolist(), [])\n",
    "\n",
    "    # Export CSV\n",
    "    pr_predictions_valid.to_csv(os.path.join(output_dir, data + '_' + str(fold) + '_PR_predictions_valid_RW.csv'), index=None, header=True)\n",
    "    pr_predictions_test.to_csv(os.path.join(output_dir, data + '_' + str(fold) + '_PR_predictions_test_RW.csv'), index=None, header=True)\n",
    "    print('')\n",
    "\n",
    "##### END LOOP\n",
    "\n",
    "# feedback\n",
    "print('')\n",
    "\n",
    "# print performance\n",
    "print('')\n",
    "print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dafcf18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "- METHOD: DI...\n",
      "------------------------------\n",
      "------------------------------\n",
      "- FOLD 0...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 1...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 2...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 3...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 4...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 5...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 6...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 7...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 8...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "------------------------------\n",
      "- FOLD 9...\n",
      "------------------------------\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "--- eta: 1.00\n",
      "--- eta: 15.00\n",
      "--- eta: 50.00\n",
      "--- eta: 70.00\n",
      "--- eta: 100.00\n",
      "\n",
      "\n",
      "\n",
      "Finished in 44.73 minutes\n"
     ]
    }
   ],
   "source": [
    "##### MODELING\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# Create the directory path for inprocessor output\n",
    "output_dir = os.path.join(res_path, 'pre1in1')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# preprocessing and inprocessing loop\n",
    "print('-' * 30)\n",
    "print('- METHOD: DI...')\n",
    "print('-' * 30)\n",
    "\n",
    "# loop through fold combinations\n",
    "for fold in range(num_folds):\n",
    "    \n",
    "    # feedback\n",
    "    print('-'*30)\n",
    "    print('- FOLD ' + str(fold) + '...')\n",
    "    print('-'*30)\n",
    "\n",
    "    ##### LOAD DATA\n",
    "    # import data subsets\n",
    "    train_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_train.pkl')\n",
    "    valid_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_valid.pkl')\n",
    "    test_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_test.pkl')\n",
    "\n",
    "    # Load the dataset\n",
    "    with open(train_path, 'rb') as file:\n",
    "        data_train = pickle.load(file)\n",
    "    with open(valid_path, 'rb') as file:\n",
    "        data_valid = pickle.load(file)\n",
    "    with open(test_path, 'rb') as file:\n",
    "        data_test = pickle.load(file)\n",
    "\n",
    "    for i in all_lambda:\n",
    "        # Disparate Impact Remover\n",
    "        di = DisparateImpactRemover(repair_level=i, sensitive_attribute=protected)\n",
    "        \n",
    "        # Transform the data\n",
    "        dataset_transf_train = di.fit_transform(data_train)\n",
    "        dataset_transf_valid = di.fit_transform(data_valid)\n",
    "        dataset_transf_test = di.fit_transform(data_test)\n",
    "        \n",
    "        ##### IN-PROCESSOR: PREJUDICE REMOVER\n",
    "        \n",
    "        # placeholders\n",
    "        pr_predictions_valid = pd.DataFrame()\n",
    "        pr_predictions_test = pd.DataFrame()\n",
    "        \n",
    "        for eta in all_eta:\n",
    "            print('--- eta: %.2f' % eta)\n",
    "            colname = 'eta_' + str(eta)\n",
    "            \n",
    "            # Fit Prejudice Remover\n",
    "            debiased_model = PrejudiceRemover(eta=eta, sensitive_attr=protected, class_attr='target')\n",
    "            debiased_model.fit(dataset_transf_train)\n",
    "            \n",
    "            # Predict validation scores\n",
    "            dataset_debiasing_valid = debiased_model.predict(dataset_transf_valid)\n",
    "            scores = dataset_debiasing_valid.scores\n",
    "            pr_predictions_valid[colname] = sum(scores.tolist(), [])\n",
    "            \n",
    "            # Predict test scores\n",
    "            dataset_debiasing_test = debiased_model.predict(dataset_transf_test)\n",
    "            scores = dataset_debiasing_test.scores\n",
    "            pr_predictions_test[colname] = sum(scores.tolist(), [])\n",
    "        \n",
    "        # Export CSV\n",
    "        pr_predictions_valid.to_csv(os.path.join(output_dir, data + '_' + str(fold) + '_PR_predictions_valid_DI_' + str(i) + '.csv'), index=None, header=True)\n",
    "        pr_predictions_test.to_csv(os.path.join(output_dir, data + '_' + str(fold) + '_PR_predictions_test_DI_' + str(i) + '.csv'), index=None, header=True)\n",
    "        print('')\n",
    "\n",
    "##### END LOOP\n",
    "\n",
    "# feedback\n",
    "print('')\n",
    "\n",
    "# print performance\n",
    "print('')\n",
    "print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94f0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
