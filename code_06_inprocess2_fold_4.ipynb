{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIR IN-PROCESSING\n",
    "\n",
    "This notebook implements the Adversarial Debiasing in-processor [(Zhang et al. 2018)](https://dl.acm.org/doi/abs/10.1145/3278721.3278779).\n",
    "\n",
    "The modeling is performed separately for each combination of training folds. This is controlled with `use_fold` variable. To fit adversarial debiasing on a different combination of training folds, set `use_fold` to a specific value and restar the kernel.\n",
    "\n",
    "A further analysis of the processor outputs is performed in `code_05_inprocess3.R`.\n",
    "\n",
    "The notebook loads the data exported in `code_00_partitinoing.ipynb` and applies in-processors. The processor predictions are exported as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "##### PACKAGES\n",
    "\n",
    "# working paths\n",
    "%run code_00_working_paths.py\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(func_path)\n",
    "\n",
    "from load_data import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parameters and preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PARAMETERS\n",
    "\n",
    "# specify data set\n",
    "# one of ['data1', 'data2', ..., 'data50']\n",
    "data = 'data50'\n",
    "\n",
    "# partitioning\n",
    "num_folds = 5\n",
    "use_fold  = 4 # one of [0, 1, ..., 4 (num_folds-1)]\n",
    "seed      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IN-PROCESSOR PARAMS\n",
    "\n",
    "adversary_loss_weight = 0.1 # other options: [0.1, 0.01, 0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RANDOM SEED\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 6)\n"
     ]
    }
   ],
   "source": [
    "##### LOAD PARTITIONING\n",
    "\n",
    "# Assuming data is in the format 'dataN' where N is the dataset number\n",
    "dataset_number = data[4:]\n",
    "\n",
    "# Create the directory path (assuming directories data1, data2, ..., data50 already exist)\n",
    "input_dir = os.path.join(data_path, 'prepared', 'data' + dataset_number)\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(input_dir, data + '_orig_test.pkl')\n",
    "\n",
    "# Load the dataset\n",
    "with open(file_path, 'rb') as file:\n",
    "    dataset_orig_test = pickle.load(file)\n",
    "    \n",
    "# Convert to dataframe and print the shape\n",
    "te = dataset_orig_test.convert_to_dataframe()[0]\n",
    "print(te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATA PREP\n",
    "\n",
    "# protected attribute\n",
    "protected           = 'race'\n",
    "privileged_groups   = [{'race': 1}] \n",
    "unprivileged_groups = [{'race': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fair processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_18376\\3867462334.py:3: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_18376\\3867462334.py:3: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_18376\\3867462334.py:6: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_18376\\3867462334.py:6: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "- FOLD 4...\n",
      "------------------------------\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.674891; batch adversarial loss: 0.899301\n",
      "epoch 1; iter: 0; batch classifier loss: 0.669905; batch adversarial loss: 0.876246\n",
      "epoch 2; iter: 0; batch classifier loss: 0.655234; batch adversarial loss: 0.880912\n",
      "epoch 3; iter: 0; batch classifier loss: 0.670982; batch adversarial loss: 0.903287\n",
      "epoch 4; iter: 0; batch classifier loss: 0.657972; batch adversarial loss: 0.892820\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635461; batch adversarial loss: 0.892677\n",
      "epoch 6; iter: 0; batch classifier loss: 0.658133; batch adversarial loss: 0.904168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652292; batch adversarial loss: 0.910475\n",
      "epoch 8; iter: 0; batch classifier loss: 0.626228; batch adversarial loss: 0.904101\n",
      "epoch 9; iter: 0; batch classifier loss: 0.624006; batch adversarial loss: 0.892282\n",
      "epoch 10; iter: 0; batch classifier loss: 0.642012; batch adversarial loss: 0.891625\n",
      "epoch 11; iter: 0; batch classifier loss: 0.713761; batch adversarial loss: 0.907638\n",
      "epoch 12; iter: 0; batch classifier loss: 0.704266; batch adversarial loss: 0.900183\n",
      "epoch 13; iter: 0; batch classifier loss: 0.618073; batch adversarial loss: 0.896351\n",
      "epoch 14; iter: 0; batch classifier loss: 0.720860; batch adversarial loss: 0.895860\n",
      "epoch 15; iter: 0; batch classifier loss: 0.675415; batch adversarial loss: 0.896365\n",
      "epoch 16; iter: 0; batch classifier loss: 0.703755; batch adversarial loss: 0.907065\n",
      "epoch 17; iter: 0; batch classifier loss: 0.700594; batch adversarial loss: 0.900410\n",
      "epoch 18; iter: 0; batch classifier loss: 0.704276; batch adversarial loss: 0.919546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.727811; batch adversarial loss: 0.905566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.670388; batch adversarial loss: 0.883778\n",
      "epoch 21; iter: 0; batch classifier loss: 0.706394; batch adversarial loss: 0.902536\n",
      "epoch 22; iter: 0; batch classifier loss: 0.707331; batch adversarial loss: 0.908708\n",
      "epoch 23; iter: 0; batch classifier loss: 0.752175; batch adversarial loss: 0.898952\n",
      "epoch 24; iter: 0; batch classifier loss: 0.759330; batch adversarial loss: 0.889300\n",
      "epoch 25; iter: 0; batch classifier loss: 0.694648; batch adversarial loss: 0.887704\n",
      "epoch 26; iter: 0; batch classifier loss: 0.786595; batch adversarial loss: 0.894373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.815185; batch adversarial loss: 0.895660\n",
      "epoch 28; iter: 0; batch classifier loss: 0.775446; batch adversarial loss: 0.874069\n",
      "epoch 29; iter: 0; batch classifier loss: 0.756509; batch adversarial loss: 0.876164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.890194; batch adversarial loss: 0.897045\n",
      "epoch 31; iter: 0; batch classifier loss: 0.874214; batch adversarial loss: 0.894805\n",
      "epoch 32; iter: 0; batch classifier loss: 0.886268; batch adversarial loss: 0.875180\n",
      "epoch 33; iter: 0; batch classifier loss: 0.961230; batch adversarial loss: 0.881192\n",
      "epoch 34; iter: 0; batch classifier loss: 0.907364; batch adversarial loss: 0.876339\n",
      "epoch 35; iter: 0; batch classifier loss: 0.948063; batch adversarial loss: 0.869599\n",
      "epoch 36; iter: 0; batch classifier loss: 0.921781; batch adversarial loss: 0.867095\n",
      "epoch 37; iter: 0; batch classifier loss: 0.901364; batch adversarial loss: 0.854650\n",
      "epoch 38; iter: 0; batch classifier loss: 0.858857; batch adversarial loss: 0.842608\n",
      "epoch 39; iter: 0; batch classifier loss: 0.924139; batch adversarial loss: 0.849454\n",
      "epoch 40; iter: 0; batch classifier loss: 0.937149; batch adversarial loss: 0.849735\n",
      "epoch 41; iter: 0; batch classifier loss: 0.991016; batch adversarial loss: 0.834271\n",
      "epoch 42; iter: 0; batch classifier loss: 0.879101; batch adversarial loss: 0.834837\n",
      "epoch 43; iter: 0; batch classifier loss: 0.887626; batch adversarial loss: 0.834859\n",
      "epoch 44; iter: 0; batch classifier loss: 0.945194; batch adversarial loss: 0.829650\n",
      "epoch 45; iter: 0; batch classifier loss: 1.048490; batch adversarial loss: 0.840202\n",
      "epoch 46; iter: 0; batch classifier loss: 1.028622; batch adversarial loss: 0.832125\n",
      "epoch 47; iter: 0; batch classifier loss: 0.969806; batch adversarial loss: 0.815297\n",
      "epoch 48; iter: 0; batch classifier loss: 1.053406; batch adversarial loss: 0.821511\n",
      "epoch 49; iter: 0; batch classifier loss: 0.898731; batch adversarial loss: 0.809243\n",
      "\n",
      "Finished in 0.06 minutes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Disable TensorFlow eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Create a TensorFlow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Define the normalization function\n",
    "def safe_normalize(x):\n",
    "    norm = tf.norm(x)\n",
    "    print(\"x:\", x)\n",
    "    print(\"norm:\", norm)\n",
    "    return tf.cond(tf.not_equal(norm, 0), lambda: x / norm, lambda: x)\n",
    "\n",
    "##### MODELING\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# Create the directory path (assuming directories data1, data2, ..., data50 already exist)\n",
    "input_dir = os.path.join(data_path, 'prepared', 'data' + dataset_number)\n",
    "output_dir = os.path.join(res_path, 'inprocess2', 'intermediate', 'data' + dataset_number)\n",
    "\n",
    "# loop through training folds\n",
    "for fold in range(num_folds):\n",
    "    \n",
    "    ##### LOAD DATA\n",
    "    \n",
    "    # select fold combination\n",
    "    if fold != use_fold:\n",
    "        continue\n",
    "\n",
    "    # feedback\n",
    "    print('-'*30)\n",
    "    print('- FOLD ' + str(fold) + '...')\n",
    "    print('-'*30)\n",
    "\n",
    "    # import data subsets\n",
    "    train_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_train.pkl')\n",
    "    valid_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_valid.pkl')\n",
    "    test_path = os.path.join(input_dir, data + '_scaled_' + str(fold) + '_test.pkl')\n",
    "        \n",
    "    # Load the dataset\n",
    "    with open(train_path, 'rb') as file:\n",
    "        data_train = pickle.load(file)\n",
    "    with open(valid_path, 'rb') as file:\n",
    "        data_valid = pickle.load(file)\n",
    "    with open(test_path, 'rb') as file:\n",
    "        data_test = pickle.load(file)\n",
    "\n",
    "    ##### MODELING\n",
    "\n",
    "    # fit adversarial debiasing\n",
    "    with tf.variable_scope('debiased_classifier', reuse=tf.AUTO_REUSE):\n",
    "        debiased_model = AdversarialDebiasing(privileged_groups     = privileged_groups,\n",
    "                                              unprivileged_groups   = unprivileged_groups,\n",
    "                                              debias                = True,\n",
    "                                              adversary_loss_weight = adversary_loss_weight,\n",
    "                                              scope_name            = 'debiased_classifier',\n",
    "                                              sess                  = sess)\n",
    "        debiased_model.fit(data_train)\n",
    "    \n",
    "    # apply the model to valid data\n",
    "    scores_valid = debiased_model.predict(data_valid).scores\n",
    "    # Flatten scores_valid to 1D\n",
    "    scores_valid_flat = scores_valid.flatten()\n",
    "    advdebias_predictions = pd.DataFrame()\n",
    "    advdebias_predictions['scores'] = scores_valid_flat\n",
    "    advdebias_predictions['targets'] = data_valid.labels.flatten()\n",
    "    advdebias_predictions.to_csv(os.path.join(output_dir, data + '_' + str(fold) + '_AD_' + str(adversary_loss_weight) + str(use_fold) + '_predictions_valid.csv'), \n",
    "                                 index=None, \n",
    "                                 header=True)\n",
    "\n",
    "    # Apply the model to test data\n",
    "    scores_test = debiased_model.predict(data_test).scores\n",
    "    scores_test_flat = scores_test.flatten()\n",
    "\n",
    "    advdebias_predictions = pd.DataFrame()\n",
    "    advdebias_predictions['scores'] = scores_test_flat\n",
    "    advdebias_predictions.to_csv(os.path.join(output_dir, data + '_' + str(fold) + '_AD_' + str(adversary_loss_weight) + str(use_fold) + '_predictions_test.csv'), \n",
    "                                 index=None, \n",
    "                                 header=True)\n",
    "\n",
    "    # print performance\n",
    "    print('')\n",
    "    print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
